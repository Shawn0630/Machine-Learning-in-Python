{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip# linear regreesion（线性回归）\n",
    "注意：python版本为3.6，\n",
    "安装TensorFlow的方法：pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\", palette=\"dark\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex1data1.txt', names=['population', 'profit'])#读取数据并赋予列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   population   profit\n0      6.1101  17.5920\n1      5.5277   9.1302\n2      8.5186  13.6620\n3      7.0032  11.8540\n4      5.8598   6.8233",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>population</th>\n      <th>profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.1101</td>\n      <td>17.5920</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.5277</td>\n      <td>9.1302</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.5186</td>\n      <td>13.6620</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.0032</td>\n      <td>11.8540</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.8598</td>\n      <td>6.8233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()#看前五行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 2 columns):\n",
      "population    97 non-null float64\n",
      "profit        97 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.6 KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 看下原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/shawn/Files/Project/ML/ex1/venv/lib/python3.7/site-packages/seaborn/regression.py:546: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot('population', 'profit', df, size=6, fit_reg=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_X(df):#读取特征\n",
    "#     \"\"\"\n",
    "#     use concat to add intersect feature to avoid side effect\n",
    "#     not efficient for big dataset though\n",
    "#     \"\"\"\n",
    "    ones = pd.DataFrame({'ones': np.ones(len(df))})#ones是m行1列的dataframe\n",
    "    data = pd.concat([ones, df], axis=1)  # 合并数据，根据列合并\n",
    "    return data.iloc[:, :-1].as_matrix()  # 这个操作返回 ndarray,不是矩阵\n",
    "\n",
    "\n",
    "def get_y(df):#读取标签\n",
    "#     '''assume the last column is the target'''\n",
    "    return np.array(df.iloc[:, -1])#df.iloc[:, -1]是指df的最后一列\n",
    "\n",
    "\n",
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())#特征缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多变量的假设 h 表示为：\\\\[{{h}_{\\theta }}\\left( x \\right)={{\\theta }_{0}}+{{\\theta }_{1}}{{x}_{1}}+{{\\theta }_{2}}{{x}_{2}}+...+{{\\theta }_{n}}{{x}_{n}}\\\\] \n",
    "这个公式中有n+1个参数和n个变量，为了使得公式能够简化一些，引入${{x}_{0}}=1$，则公式转化为：  \n",
    "此时模型中的参数是一个n+1维的向量，任何一个训练实例也都是n+1维的向量，特征矩阵X的维度是 m*(n+1)。 因此公式可以简化为：${{h}_{\\theta }}\\left( x \\right)={{\\theta }^{T}}X$，其中上标T代表矩阵转置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b5ae2dbe79da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# 这个函数是旧金山的一个大神Lucas Shen写的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0;31m# placeholder for graph input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ],
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error"
    }
   ],
   "source": [
    "def linear_regression(X_data, y_data, alpha, epoch, optimizer=tf.train.GradientDescentOptimizer):# 这个函数是旧金山的一个大神Lucas Shen写的\n",
    "      # placeholder for graph input\n",
    "    X = tf.placeholder(tf.float32, shape=X_data.shape)\n",
    "    y = tf.placeholder(tf.float32, shape=y_data.shape)\n",
    "\n",
    "    # construct the graph\n",
    "    with tf.variable_scope('linear-regression'):\n",
    "        W = tf.get_variable(\"weights\",\n",
    "                            (X_data.shape[1], 1),\n",
    "                            initializer=tf.constant_initializer())  # n*1\n",
    "\n",
    "        y_pred = tf.matmul(X, W)  # m*n @ n*1 -> m*1\n",
    "\n",
    "        loss = 1 / (2 * len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)  # (m*1).T @ m*1 = 1*1\n",
    "\n",
    "    opt = optimizer(learning_rate=alpha)\n",
    "    opt_operation = opt.minimize(loss)\n",
    "\n",
    "    # run the session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        loss_data = []\n",
    "\n",
    "        for i in range(epoch):\n",
    "            _, loss_val, W_val = sess.run([opt_operation, loss, W], feed_dict={X: X_data, y: y_data})\n",
    "            loss_data.append(loss_val[0, 0])  # because every loss_val is 1*1 ndarray\n",
    "\n",
    "            if len(loss_data) > 1 and np.abs(loss_data[-1] - loss_data[-2]) < 10 ** -9:  # early break when it's converged\n",
    "                # print('Converged at epoch {}'.format(i))\n",
    "                break\n",
    "\n",
    "    # clear the graph\n",
    "    tf.reset_default_graph()\n",
    "    return {'loss': loss_data, 'parameters': W_val}  # just want to return in row vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data1.txt', names=['population', 'profit'])#读取数据，并赋予列名\n",
    "\n",
    "data.head()#看下数据前5行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算代价函数\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{2m}\\sum\\limits_{i=1}^{m}{{{\\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}} \\right)}^{2}}}$$\n",
    "其中：\\\\[{{h}_{\\theta }}\\left( x \\right)={{\\theta }^{T}}X={{\\theta }_{0}}{{x}_{0}}+{{\\theta }_{1}}{{x}_{1}}+{{\\theta }_{2}}{{x}_{2}}+...+{{\\theta }_{n}}{{x}_{n}}\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape, type(X))\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape, type(y))\n",
    "#看下数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(X.shape[1])#X.shape[1]=2,代表特征数n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def lr_cost(theta, X, y):\n",
    "#     \"\"\"\n",
    "#     X: R(m*n), m 样本数, n 特征数\n",
    "#     y: R(m)\n",
    "#     theta : R(n), 线性回归的参数\n",
    "#     \"\"\"\n",
    "    m = X.shape[0]#m为样本数\n",
    "\n",
    "    inner = X @ theta - y  # R(m*1)，X @ theta等价于X.dot(theta)\n",
    "\n",
    "    # 1*m @ m*1 = 1*1 in matrix multiplication\n",
    "    # but you know numpy didn't do transpose in 1d array, so here is just a\n",
    "    # vector inner product to itselves\n",
    "    square_sum = inner.T @ inner\n",
    "    cost = square_sum / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr_cost(theta, X, y)#返回theta的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch gradient decent（批量梯度下降）\n",
    "$${{\\theta }_{j}}:={{\\theta }_{j}}-\\alpha \\frac{\\partial }{\\partial {{\\theta }_{j}}}J\\left( \\theta  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    inner = X.T @ (X @ theta - y)  # (m,n).T @ (m, 1) -> (n, 1)，X @ theta等价于X.dot(theta)\n",
    "\n",
    "    return inner / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def batch_gradient_decent(theta, X, y, epoch, alpha=0.01):\n",
    "#   拟合线性回归，返回参数和代价\n",
    "#     epoch: 批处理的轮数\n",
    "#     \"\"\"\n",
    "    cost_data = [lr_cost(theta, X, y)]\n",
    "    _theta = theta.copy()  # 拷贝一份，不和原来的theta混淆\n",
    "\n",
    "    for _ in range(epoch):\n",
    "        _theta = _theta - alpha * gradient(_theta, X, y)\n",
    "        cost_data.append(lr_cost(_theta, X, y))\n",
    "\n",
    "    return _theta, cost_data\n",
    "#批量梯度下降函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epoch = 500\n",
    "final_theta, cost_data = batch_gradient_decent(theta, X, y, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_theta\n",
    "#最终的theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cost_data\n",
    "# 看下代价数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 计算最终的代价\n",
    "lr_cost(final_theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize cost data（代价数据可视化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.tsplot(cost_data, time=np.arange(epoch+1))\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('cost')\n",
    "plt.show()\n",
    "#可以看到从第二轮代价数据变换很大，接下来平稳了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b = final_theta[0] # intercept，Y轴上的截距\n",
    "m = final_theta[1] # slope，斜率\n",
    "\n",
    "plt.scatter(data.population, data.profit, label=\"Training data\")\n",
    "plt.plot(data.population, data.population*m + b, label=\"Prediction\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- 选修章节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('ex1data2.txt', names=['square', 'bedrooms', 'price'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 标准化数据\n",
    "最简单的方法是令：\n",
    "\n",
    " \n",
    "\n",
    "其中  是平均值，sn 是标准差。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = normalize_feature(raw_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. multi-var batch gradient decent（多变量批量梯度下降）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape, type(X))\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape, type(y))#看下数据的维度和类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.01#学习率\n",
    "theta = np.zeros(X.shape[1])#X.shape[1]：特征数n\n",
    "epoch = 500#轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_theta, cost_data = batch_gradient_decent(theta, X, y, epoch, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.tsplot(time=np.arange(len(cost_data)), data = cost_data)\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('cost', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. learning rate（学习率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "base = np.logspace(-1, -5, num=4)\n",
    "candidate = np.sort(np.concatenate((base, base*3)))\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epoch=50\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "for alpha in candidate:\n",
    "    _, cost_data = batch_gradient_decent(theta, X, y, epoch, alpha=alpha)\n",
    "    ax.plot(np.arange(epoch+1), cost_data, label=alpha)\n",
    "\n",
    "ax.set_xlabel('epoch', fontsize=18)\n",
    "ax.set_ylabel('cost', fontsize=18)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('learning rate', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. normal equation（正规方程）\n",
    "正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\\frac{\\partial }{\\partial {{\\theta }_{j}}}J\\left( {{\\theta }_{j}} \\right)=0$ 。\n",
    " 假设我们的训练集特征矩阵为 X（包含了${{x}_{0}}=1$）并且我们的训练集结果为向量 y，则利用正规方程解出向量 $\\theta ={{\\left( {{X}^{T}}X \\right)}^{-1}}{{X}^{T}}y$ 。\n",
    "上标T代表矩阵转置，上标-1 代表矩阵的逆。设矩阵$A={{X}^{T}}X$，则：${{\\left( {{X}^{T}}X \\right)}^{-1}}={{A}^{-1}}$\n",
    "\n",
    "梯度下降与正规方程的比较：\n",
    "\n",
    "梯度下降：需要选择学习率α，需要多次迭代，当特征数量n大时也能较好适用，适用于各种类型的模型\t\n",
    "\n",
    "正规方程：不需要选择学习率α，一次计算得出，需要计算${{\\left( {{X}^{T}}X \\right)}^{-1}}$，如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为O(n3)，通常来说当n小于10000 时还是可以接受的，只适用于线性模型，不适合逻辑回归模型等其他模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 正规方程\n",
    "def normalEqn(X, y):\n",
    "    theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "final_theta2=normalEqn(X, y)#感觉和批量梯度下降的theta的值有点差距\n",
    "final_theta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the tensorflow graph over several optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_data = get_X(data)\n",
    "print(X_data.shape, type(X_data))\n",
    "\n",
    "y_data = get_y(data).reshape(len(X_data), 1)  # special treatment for tensorflow input data\n",
    "print(y_data.shape, type(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epoch = 2000\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer_dict={'GD': tf.train.GradientDescentOptimizer,\n",
    "                'Adagrad': tf.train.AdagradOptimizer,\n",
    "                'Adam': tf.train.AdamOptimizer,\n",
    "                'Ftrl': tf.train.FtrlOptimizer,\n",
    "                'RMS': tf.train.RMSPropOptimizer\n",
    "               }\n",
    "results = []\n",
    "for name in optimizer_dict:\n",
    "    res = linear_regression(X_data, y_data, alpha, epoch, optimizer=optimizer_dict[name])\n",
    "    res['name'] = name\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "for res in results: \n",
    "    loss_data = res['loss']\n",
    "    \n",
    "#     print('for optimizer {}'.format(res['name']))\n",
    "#     print('final parameters\\n', res['parameters'])\n",
    "#     print('final loss={}\\n'.format(loss_data[-1]))\n",
    "    ax.plot(np.arange(len(loss_data)), loss_data, label=res['name'])\n",
    "\n",
    "ax.set_xlabel('epoch', fontsize=18)\n",
    "ax.set_ylabel('cost', fontsize=18)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('different optimizer', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}